{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d287b2cb",
   "metadata": {},
   "source": [
    "Regression - real value output\n",
    "\n",
    "Linear regression is a regression model that estimates the relationship between one independent variable and one dependent variable using a straight line. Both variables should be quantitative."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8358d939",
   "metadata": {},
   "source": [
    "Classification - discreet value output (binary)\n",
    "\n",
    "Logistic regression is a statistical analysis method to predict a binary outcome, such as yes or no, based on prior observations of a data set. A logistic regression model predicts a dependent data variable by analyzing the relationship between one or more existing independent variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a626a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "data = []\n",
    "with open('dataset.csv', 'r') as f:\n",
    "    reader = csv.reader(f)\n",
    "    header = next(reader)\n",
    "    for row in reader:\n",
    "        data.append([row[1], row[-1]])\n",
    "\n",
    "print(data)\n",
    "\n",
    "x = [float(d[0]) for d in data]\n",
    "y = [float(d[1]) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9fdcc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "min_val = min(x)\n",
    "min_idx = x.index(min_val)\n",
    "\n",
    "max_val = max(x)\n",
    "max_idx = x.index(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bfa92be",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(x, y)\n",
    "plt.plot([x[min_idx], x[max_idx]], [y[min_idx], y[max_idx]], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee817b2f",
   "metadata": {},
   "source": [
    "Case study: Determine the price of a laptop based on processor turbo frequency.\n",
    "Your friend wants to buy a new laptop and he asks for your advice on the recommended processor frequency. He has a budget in mind, but you would like to be prepared in case he increase the budget."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9859d734",
   "metadata": {},
   "source": [
    "PREDICTION - the outcome determined by the algorithm given an input value\n",
    "\n",
    "FORMULA: f(x) = wx + b\n",
    "\n",
    "w, b - parameters (weights)\n",
    "\n",
    "y_hat = [f(x) for i = 0...len(x)-1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a878b926",
   "metadata": {},
   "source": [
    "COST FUNCTION - the total error between predicted outcomes and the actual outcomes\n",
    "\n",
    "SQUARED ERROR COST FUNCTION\n",
    "\n",
    "m = len(dataset)\n",
    "\n",
    "FORMULA: J(w, b) = 1/2m * sum((y_hat[i] - y[i])^2 for i = 0...len(x)-1)\n",
    "\n",
    "loss[i] = (y_hat[i] - y[i])^2\n",
    "\n",
    "J(w, b) = 1/2m * sum(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "216d0de6",
   "metadata": {},
   "source": [
    "OBJECTIVE: minimize the cost function\n",
    "minimize J(w, b) over w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4ec17a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(xi, w, b):\n",
    "    # Predict the outcome y_hat of xi\n",
    "    # given the values of w and b\n",
    "    # Compute f(x)\n",
    "    # ADD YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c3bf313",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_squared_error(y, y_hat):\n",
    "    # Compute the total error given the correct outputs and the predictions\n",
    "    m = len(y)\n",
    "    # ADD YOUR CODE HERE\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4d06530",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 0.5\n",
    "b = 2\n",
    "\n",
    "x = [0, 5, 10]\n",
    "y = [predict(xi, w, b) for xi in x]\n",
    "plt.plot(x, y, color=\"red\")\n",
    "plt.xlim(0, 10)\n",
    "plt.ylim(0, 10)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35490ba5",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_x = [0, 1, 2]\n",
    "test_y = [0, 1, 2]\n",
    "\n",
    "plt.scatter(test_x, test_y)\n",
    "plt.plot([test_x[0], test_x[-1]], [test_y[0], test_y[-1]], color=\"red\")\n",
    "plt.show()\n",
    "\n",
    "test_b = 0\n",
    "cost_w = [-4, -3, -2, -1, 0, 1, 2, 3, 4, 5, 6]\n",
    "cost_mse = []\n",
    "\n",
    "for test_w in cost_w:\n",
    "    test_y_hat = [predict(test_y[i], test_w, test_b) for i in range(len(test_y))]\n",
    "    cost_mse.append(mean_squared_error(test_y, test_y_hat))\n",
    "\n",
    "plt.scatter(cost_w, cost_mse)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dd6ea7",
   "metadata": {},
   "source": [
    "GRADIENT DESCENT - an optimization algorithm used to minimize some function by iteratively moving in the direction of steepest descent as defined by the negative of the gradient.\n",
    "\n",
    "FORMULA:\n",
    "\n",
    "w = w - α * d/dw * J(w, b)\n",
    "\n",
    "b = b - α * d/db * J(w, b)\n",
    "\n",
    "α - learning rate - how fast we move\n",
    "\n",
    "J(w, b) = 1/2m * sum((y_hat[i] - y[i])^2 for i = 0...len(x)-1)\n",
    "\n",
    "d/dw * J(w, b) = 1/m * sum((y_hat[i] - y[i]) * x[i] for i = 0...m-1)\n",
    "\n",
    "d/db * J(w, b) = 1/m * sum((y_hat[i] - y[i]) for i = 0...m-1)\n",
    "\n",
    "Demonstration: https://www.coursera.org/learn/machine-learning/lecture/lgSMj/gradient-descent-for-linear-regression\n",
    "\n",
    "FINAL FORMULAS:\n",
    "\n",
    "w = w - α * 1/m * sum((y_hat[i] - y[i]) * x[i] for i = 0...m-1)\n",
    "\n",
    "b = b - α * 1/m * sum((y_hat[i] - y[i]) for i = 0...m-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccec600",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparam\n",
    "alpha = 0.1\n",
    "\n",
    "def gradient_descent_step(w, b, x, y):\n",
    "    # Take a step in the steepest direction \n",
    "    # Compute the new values for w and b\n",
    "    global alpha\n",
    "    m = len(x)\n",
    "    \n",
    "    # ADD YOUR CODE HERE\n",
    "    # Compute y_hat\n",
    "    \n",
    "    # Compute w = w - α * 1/m * sum((y_hat[i] - y[i]) * x[i] for i = 0...m-1)\n",
    "    \n",
    "    # Compute b = b - α * 1/m * sum((y_hat[i] - y[i]) for i = 0...m-1)\n",
    "    \n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dedfe9d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset env\n",
    "test_x = [0, 1, 2]\n",
    "test_y = [0, 1, 2]\n",
    "\n",
    "test_b = 0\n",
    "test_w = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc399bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(10):\n",
    "    test_w, test_b = gradient_descent_step(test_w, test_b, test_x, test_y)\n",
    "print(test_w, test_b)\n",
    "\n",
    "plt.scatter(test_x, test_y)\n",
    "plt.plot([test_x[0], test_x[-1]], [predict(test_x[0], test_w, test_b), predict(test_x[-1], test_w, test_b)], color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6a3b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WORKING WITH REAL DATA\n",
    "# RESET PARAMS\n",
    "w = 0\n",
    "b = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d0616f",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1000\n",
    "\n",
    "for i in range(EPOCHS):\n",
    "    w, b = gradient_descent_step(w, b, x, y)\n",
    "print(w, b)\n",
    "\n",
    "plt.scatter(x, y)\n",
    "plt.plot([x[min_idx], x[max_idx]], [predict(x[min_idx], w, b), predict(x[max_idx], w, b)], color=\"red\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "f544ce1a915a9875fad91c894e2c0bcad4b7a79945aa6027ef3ad27810072aa6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
